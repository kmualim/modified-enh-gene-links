{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents of Notebook: \n",
    "\n",
    "The contents of this notebook details the models applied to the enhancer gene link (ABC.Score) + neural network embeddings from the Basset 2016 Model <br> \n",
    "\n",
    "\n",
    "[Regression dataset](#linearregdataset)\n",
    "<a href='#linearregdataset'></a>\n",
    "\n",
    "I explored using Linear models like Linear Regression, Lasso, Ridge as well as Nonlinear models like Random Forest Regressor and Gradient Boosted Trees. \n",
    "[Model analysis overview](#linearmodeloverview)\n",
    "<a href='#linearmodeloverview'></a>\n",
    "\n",
    "### Models: \n",
    "1. [Linear Regression Base Model](#linearbase)<a href='#linearbase'></a> with default parameters \n",
    "2. [Lasso](#lasso)<a href='#lasso'></a> \n",
    "3. [Ridge Base Model](#ridge)<a href='#ridge'></a>\n",
    "4. [Ridge w/ Parameter Tuning](#bestridge)<a href='#bestridge'></a>\n",
    "5. [Random Forest Base Model](#rfrbase)<a href='#rfrbase'></a>\n",
    "6. [Boosting algorithm with Random Forest model](#rfrboosting)<a href='#rfrboosting'></a>\n",
    "Essentially, we applied a boosting algorithm where at each iteration the model fits the residual in the hopes that the final residual ends up being \"noise\" that the model can no longer learn from\n",
    "7. [Random Forest Model after Classification](#rfrclassification)<a href='#rfrclassification'></a>\n",
    "8. [Random Forest Model Base Model](#rfrbaseclass)<a href='#rfrbaseclass'></a>\n",
    "9. [Random Forest Model w/o prior classification](#bestRFRnoclass)<a href='#bestRFRnoclass'></a>\n",
    "10. [Gradient Boosting Regressor](#GBRbase)<a href='#GBRbase'></a> with default parameters\n",
    "11. [Gradient Boosting Regressor w/ Parameter Tuning](#GBRbest)<a href='#GBRbest'></a>\n",
    "\n",
    "After this initial test on the various models, I decided to look deeper into the data distribution. \n",
    "\n",
    "The neural network embeddings are from a sequence to chromatin accessibility Basset model from David Kelley's 2016 Paper. \n",
    "\n",
    "In the following notebook, I try to answer some fundamental questions about the dataset such as : \n",
    "1. Can we artificially curate the dataset to allow better fitting for linear models \n",
    "2. Why is there a characteristic vertical line present in the fitting of the following models \n",
    "--- the correlation graphs of the models used in this notebook had a vertical line that corresponded to the y-intercept of the linear model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "import pickle\n",
    "import joblib\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='datapaths'></a>\n",
    "#### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = np.load(\"/mnt/lab_data2/kmualim/enhancer_gene_anlysis/datasets/all_dataset/gene_labels_all.npy\", allow_pickle=True)\n",
    "express_1 = pickle.load(open(\"/mnt/lab_data2/kmualim/enhancer_gene_anlysis/datasets/all_dataset/embeddings_all_w_gene.p\",\"rb\"))\n",
    "expression = pd.read_csv(\"/mnt/lab_data2/kmualim/enhancer_gene_anlysis/datasets/K562.Genes.TPM.txt\", sep=\" \", header=None)\n",
    "expression.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataprocessing'></a>\n",
    "#### Functions for combining and splitting data inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Appending labels to expression table \n",
    "## 0 for non-expressed, 0 for expressed\n",
    "label_1=[]\n",
    "for i in expression[1]: \n",
    "    if i>1: \n",
    "        label_1.append(1)\n",
    "    else: \n",
    "        label_1.append(0)\n",
    "\n",
    "expression[2] = label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "def get_expression(express_dict, y_valid_labels): \n",
    "    x_val=[]\n",
    "    for i in y_valid_labels[0]:\n",
    "        x_val.append(express_dict[i])\n",
    "    x_values = np.vstack(x_val)\n",
    "    return x_values\n",
    "    \n",
    "def get_list(y_valid):\n",
    "    y_valid_el = []\n",
    "    for i in y_valid: \n",
    "        y_valid_el.append(i)\n",
    "    return y_valid_el\n",
    "\n",
    "# creating feature spaces \n",
    "def get_train_valid_split(labels, expression_dict, expression, classify=False):\n",
    "    y_train, y_rem = train_test_split(labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "    y_valid, y_test = train_test_split(y_rem, test_size=0.25, random_state=42, shuffle=True)\n",
    "    y_train_el = get_list(y_train) \n",
    "    y_valid_el = get_list(y_valid) \n",
    "    y_test_el = get_list(y_test) \n",
    "    y_train_labels = expression[expression[0].isin(y_train_el)]\n",
    "    y_valid_labels = expression[expression[0].isin(y_valid_el)]\n",
    "    y_test_labels = expression[expression[0].isin(y_test_el)]\n",
    "    x_train = get_expression(expression_dict, y_train_labels)\n",
    "    x_valid = get_expression(expression_dict, y_valid_labels)\n",
    "    x_test = get_expression(expression_dict, y_test_labels)\n",
    "    #if classify: \n",
    "    y_train_c, y_valid_c, y_test_c = get_class_labels(y_train_labels, y_valid_labels, y_test_labels)\n",
    "    #else: \n",
    "    y_train_r, y_valid_r, y_test_r = get_reg_labels(y_train_labels, y_valid_labels, y_test_labels)\n",
    "    return x_train, x_valid, x_test, y_train_r, y_valid_r, y_test_r, y_train_c, y_valid_c, y_test_c\n",
    "\n",
    "def get_class_labels(y_train_labels, y_valid_labels, y_test_labels):\n",
    "        y_train = y_train_labels[2].values\n",
    "        y_valid = y_valid_labels[2].values\n",
    "        y_test = y_test_labels[2].values \n",
    "        return y_train, y_valid, y_test\n",
    "    \n",
    "def get_reg_labels(y_train_labels, y_valid_labels, y_test_labels):\n",
    "        y_train = y_train_labels[1].values\n",
    "        y_valid = y_valid_labels[1].values\n",
    "        y_test = y_test_labels[1].values\n",
    "        return y_train, y_valid, y_test\n",
    "    \n",
    "    \n",
    "    \n",
    "%matplotlib inline\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(y_valid_preds, y_valid): \n",
    "    print(\"Spearman R\", spearmanr(y_valid_preds,np.arcsinh(y_valid)))\n",
    "    print(\"Pearson R\", pearsonr(y_valid_preds,np.arcsinh(y_valid)))\n",
    "    plt.plot(y_valid_preds, np.arcsinh(y_valid), 'ro', markersize=2)\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Correlation graph')\n",
    "    return plt\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = mean_squared_error(np.arcsinh(test_labels), predictions)\n",
    "    plt = plot(predictions, test_labels)\n",
    "    #mape = 100 * np.mean(errors / test_labels)\n",
    "    #accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('MSError: {:0.4f} '.format(errors))\n",
    "    #print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return errors, plt #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='datafiles'></a>\n",
    "#### Data files and corresponding names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test, y_train_labels, y_valid_labels, y_test_labels = get_train_valid_split(labels, express_1, expression, classify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez(\"train_classification_labels_abc_large.npz\",train_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linearmodeloverview'></a>\n",
    "#### Overview of analysis [ABC.Score]\n",
    " \n",
    "Linear Regression : <br>\n",
    "\n",
    "SPEARMAN train,valid: 0.58197, 0.51572 <br>\n",
    "PEARSON train, valid: 0.541520, 0.43851 <br>\n",
    "\n",
    "Lasso: <br>\n",
    "\n",
    "alpha=0.001 <br>\n",
    "../scripts/ABC.Score_lascv.joblib <br>\n",
    "SPEARMAN train, valid: 0.5404, 0.5288 <br>\n",
    "PEARSON train, valid: 0.4479, 0.4259 <br>\n",
    "\n",
    "Ridge : <br>\n",
    "\n",
    "Alpha = 0.0001 <br>\n",
    "../scripts/test_models/ABC.Score_ridgecv_0.0001-0.01.joblib <br>\n",
    "SPEARMAN train, valid: 0.55974, 0.54069 <br>\n",
    "PEARSON train, valid: 0.51249, 0.47275 <br>\n",
    "\n",
    "\n",
    "Random Forest Regressor <br>\n",
    "[BASE MODEL]: <br>\n",
    "SPEARMAN train, valid, test:0.88130, 0.51643, 0.5678 <br>\n",
    "PEARSON train, valid, test : 0.9280, 0.49752, 0.5409 <br>\n",
    "\n",
    "[BEST MODEL AUGUST 5] : ../scripts/ABC.Score_all_RFR_cv10.joblib <br>\n",
    "SPEARMAN train, valid = 0.73176, 0.5694 <br>\n",
    "PEARSON train,valid = 0.738383, 0.5581036 <br>\n",
    "\n",
    "\n",
    "GRADIENT BOOSTED TREES: <br>\n",
    "\n",
    "GBT/GBR_base_ABC_large.joblib <br>\n",
    "[BASE MODEL]: <br>\n",
    "SPEARMAN train, valid, test: 0.63468, 0.571675 <br>\n",
    "PEARSON train, valid, test : 0.639225, 0.581997 <br>\n",
    "\n",
    "[BEST MODEL AUGUST 5] :../scripts/ABC.Score_all_GBT_cv10.joblib <br>\n",
    "{'learning_rate': 0.05,\n",
    " 'max_depth': 18,\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_leaf': 15,\n",
    " 'min_samples_split': 15,\n",
    " 'n_estimators': 83}\n",
    "\n",
    "SPEARMAN train, valid, test: 0.86290, 0.55637 <br>\n",
    "PEARSON train, valid, test : 0.896418, 0.56607 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linearregdataset'></a>\n",
    "#### path to Linear regression dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reg, x_valid_reg, x_test_reg, y_train_reg, y_valid_reg, y_test_reg, y_train_labels, y_valid_labels, y_test_labels = get_train_valid_split(labels, express_1, expression, classify=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing all training_data \n",
    "np.savez(\"datasets/train_valid_test_all/x_train_reg_all.npz\", x_train_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/x_valid_reg_all.npz\", x_valid_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/x_test_reg_all.npz\", x_test_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/y_train_reg_all.npz\", y_train_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/y_valid_reg_all.npz\", y_valid_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/y_test_reg_all.npz\", y_test_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/train_gene_labels_reg_all.npz\", y_train_labels)\n",
    "np.savez(\"datasets/train_valid_test_all/valid_gene_labels_reg_all.npz\", y_valid_labels)\n",
    "np.savez(\"datasets/train_valid_test_all/test_gene_labels_reg_all.npz\", y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_after_class(y_valid_preds, y_valid): \n",
    "    print(\"Spearman R\", spearmanr(y_valid_preds,np.arcsinh(y_valid)))\n",
    "    print(\"Pearson R\", pearsonr(y_valid_preds,np.arcsinh(y_valid)))\n",
    "    plt.plot(y_valid_preds, np.arcsinh(y_valid), 'ro', markersize=2)\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Correlation graph')\n",
    "    return plt\n",
    "\n",
    "def get_number_of_zeros(test_labels, preds): \n",
    "    num_test_zero=0\n",
    "    num_pred_zero=0\n",
    "    for i in range(len(test_labels)): \n",
    "        if test_labels[i]==0 and preds[i]!=0:\n",
    "            num_test_zero+=1\n",
    "        if test_labels[i]!=0 and preds[i]==0:\n",
    "            num_pred_zero+=1\n",
    "    return num_test_zero, num_pred_zero\n",
    "    \n",
    "def eval_after_class(model, test_features, test_labels, test_class_labels, include_zeros=True):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = mean_squared_error(np.arcsinh(test_labels), (predictions*test_class_labels))\n",
    "    final_preds = predictions*test_class_labels\n",
    "    num_test_zero, num_pred_zero = get_number_of_zeros(test_labels, test_class_labels)\n",
    "    if include_zeros:\n",
    "        plt = plot_after_class(final_preds, test_labels)\n",
    "    else: \n",
    "        plt = plot_after_class(final_preds[final_preds!=0], test_labels[final_preds!=0])\n",
    "    #mape = 100 * np.mean(errors / test_labels)\n",
    "    #accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('MSError: {:0.4f} degrees.'.format(errors))\n",
    "    \n",
    "    print(\"Number of Predictions!=0 and Actual==0:\", num_test_zero)\n",
    "    print(\"Number of Predictions==0 and Actual!=0:\", num_pred_zero)\n",
    "    print(\"Number of total Predictions:\", len(final_preds))\n",
    "    #print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return errors, predictions, plt #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing only the labels that are 1 \"expressed\" \n",
    "use as input for linear regression \n",
    "\n",
    "Reduces training data from ~16k to just ~7k "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='expressedgenespath'></a>\n",
    "#### paths to expressed genes datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/7580_abc_large_expressed.npz\", train_big)\n",
    "np.savez(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/7580_abc_large_expressed_labels.npz\", train_labels_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big = np.load(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/7580_abc_large_expressed.npz\")['arr_0']\n",
    "train_labels_big = np.load(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/7580_abc_large_expressed_labels.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_big, x_valid_big, y_train_big, y_valid_big = train_test_split(train_big, train_labels_big, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_big))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linreg_AFTERCLASS trained on ~6k examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(linreg_AFTERCLASS, open(\"linreg/linreg_abc_large_after_classification_TPM1.joblib\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting y-intercept of linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_AFTERCLASS = joblib.load(\"linreg/linreg_abc_large_after_classification_TPM1.joblib\")\n",
    "linreg_AFTERCLASS.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the distribution of arcsinh(TPM) values , manually picking out only the values where TPM != 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a lot of the zeros are also from the arcsinh of the thing \n",
    "#print(len(y_train_reg[y_train_reg==0]))\n",
    "plt.hist(np.arcsinh(y_train_reg[y_train_reg!=0]), bins=100)\n",
    "plt.savefig(\"/oak/stanford/groups/akundaje/projects/egl_analysis/images/abc_large_y_distribution.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_TRAIN LABELS are np.arcsinh(TPM) <br>\n",
    "Looking at the distribution, thresholding labels to just consider np.arcsinh(TPM) values above 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_th(y_valid_preds, y_valid): \n",
    "\n",
    "    plt.plot(y_valid_preds, y_valid, 'ro', markersize=2)\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Correlation graph')\n",
    "    return plt\n",
    "\n",
    "def eval_th(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = mean_squared_error(test_labels,predictions)\n",
    "    print(\"Spearman R\", spearmanr(predictions,test_labels))\n",
    "    print(\"Pearson R\", pearsonr(predictions, test_labels))\n",
    "    #plt = plot_th(predictions, test_labels)\n",
    "    #mape = 100 * np.mean(errors / test_labels)\n",
    "    #accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('MSError: {:0.4f} '.format(errors))\n",
    "    #print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return errors#, plt #accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.arcsinh(y_train_reg)\n",
    "rel = y_val[y_val>0.5]\n",
    "x_train_rel = x_train_reg[y_val>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_1 = np.arcsinh(y_valid_reg)\n",
    "y_val_rel = y_val_1[y_val_1>0.5]\n",
    "x_valid_rel = x_valid_reg[y_val_1>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rel))\n",
    "print(len(y_val_rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(rel, bins=100)\n",
    "plt.savefig(\"/oak/stanford/groups/akundaje/projects/egl_analysis/images/abc_large_y_distribution_threshold_0.5TPM.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting linear regression using only TPM y values above a threshold of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_th = LinearRegression()\n",
    "linreg_th.fit(x_train_rel, rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_th.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, plt = eval_th(linreg_th, x_train_rel, rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/oak/stanford/groups/akundaje/projects/egl_analysis/images/abc_large_y_distribution_threshold_0.5_train_linreg.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, plt = evaluate(linreg_th, x_valid_rel, y_val_rel)\n",
    "plt.xlim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/oak/stanford/groups/akundaje/projects/egl_analysis/images/abc_large_y_distribution_threshold_0.5_valid_linreg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(linreg_th, open(\"linreg/linreg_threshold_0.5_abc_large.joblib\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_TRAIN LABELS are np.arcsinh(TPM) <br>\n",
    "Thresholding labels to just consider np.arcsinh(TPM) values above 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.arcsinh(y_train_reg)\n",
    "rel = y_val[y_val>1.0]\n",
    "x_train_rel = x_train_reg[y_val>1.0]\n",
    "\n",
    "y_val_1 = np.arcsinh(y_valid_reg)\n",
    "y_val_rel = y_val_1[y_val_1>1.0]\n",
    "x_valid_rel = x_valid_reg[y_val_1>1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(rel, bins=100)\n",
    "plt.savefig(\"/oak/stanford/groups/akundaje/projects/egl_analysis/images/abc_large_y_distribution_threshold_1.0.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting linear regression using only TPM y values above a threshold of 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_th_1 = LinearRegression()\n",
    "linreg_th_1.fit(x_train_rel, rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_th_1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, plt = eval_th(linreg_th_1, x_train_rel, rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/oak/stanford/groups/akundaje/projects/egl_analysis/images/abc_large_y_distribution_threshold_1.0_train_linreg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, plt = evaluate(linreg_th_1, x_valid_rel, y_val_rel)\n",
    "plt.xlim(0,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/oak/stanford/groups/akundaje/projects/egl_analysis/images/abc_large_y_distribution_threshold_1.0_valid_linreg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(linreg_th_1, open(\"linreg/linreg_threshold_1_abc_large.joblib\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH ON TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linearbase'></a>\n",
    "### Linear Regression BASE MODEL (ABC.Score + Neural network embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = joblib.load(\"/mnt/lab_data2/kmualim/Jamboree_data/models/abc_all/test_models/ABC.Score_linreg.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, plt  = evaluate(linreg, x_train, np.arcsinh(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/oak/stanford/groups/akundaje/projects/egl_analysis/images/abc_large_y_distribution_threshold_1.0_train_linreg.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH ON VALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, plt = evaluate(linreg, x_valid, np.arcsinh(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/oak/stanford/groups/akundaje/projects/egl_analysis/images/abc_large_y_distribution_threshold_1.0_valid_linreg.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lasso'></a>\n",
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = joblib.load(\"/mnt/lab_data2/kmualim/Jamboree_data/models/abc_all/test_models/ABC.Score_lascv.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH FOR TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, plt = evaluate(lasso, x_train, np.arcsinh(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/oak/stanford/groups/akundaje/projects/egl_analysis/images/abc_large_y_distribution_train_lasso.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH FOR VALID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, plt = evaluate(lasso, x_valid, np.arcsinh(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/oak/stanford/groups/akundaje/projects/egl_analysis/images/abc_large_y_distribution_valid_lasso.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ridge'></a>\n",
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = joblib.load(\"/mnt/lab_data2/kmualim/Jamboree_data/models/abc_all/test_models/ABC.Score_ridge_base.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH ON TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ridge, x_train, np.arcsinh(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH ON VALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate(ridge, x_valid, np.arcsinh(y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bestridge'></a>\n",
    "#### BEST RIDGE CV MODEL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge = joblib.load(\"/mnt/lab_data2/kmualim/Jamboree_data/models/abc_all/test_models/ABC.Score_ridgecv_0.0001-0.01.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH ON TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model_ridge, x_train, np.arcsinh(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH ON VALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model_ridge, x_valid, np.arcsinh(y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rfrbase'></a>\n",
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor()\n",
    "print(\"Modeling is fitting ...\")\n",
    "regressor.fit(x_train,np.arcsinh(y_train))\n",
    "y_valid_preds = regressor.predict(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH ON TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = regressor.predict(x_train)\n",
    "plot(y_train_preds, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH ON VALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(y_valid_preds, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH ON TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = regressor.predict(x_test)\n",
    "plot(y_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(regressor, open(\"RFR/RFR_base_ABC_large.joblib\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rfrboosting'></a>\n",
    "### Random Forest Regressor Residual Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 20 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_RFR = np.load(\"/mnt/lab_data2/kmualim/Jamboree_data/scripts/src/RF_best_iteration_residual.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_RFR = np.load(\"/mnt/lab_data2/kmualim/Jamboree_data/scripts/src/RF_best_iteration.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(actual_RFR, np.arcsinh(train_big_labels),  'ro')\n",
    "plt.xlabel(\"Predictions\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(residual_RFR, np.arcsinh(train_big_labels),  'ro')\n",
    "plt.xlabel(\"Predictions\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_RFR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rfrclassification'></a>\n",
    "### Evaluating Random Forest Regressor after prior classification\n",
    "-- final regressor is on expressed genes\n",
    "-- after logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aug11_class_model = joblib.load(\"/mnt/lab_data2/kmualim/Jamboree_data/models/abc_all/Aug11_ABC.Score_after_classification_all_RFR_cv10.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.load(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/train_classification_labels_abc_large.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.load(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/test_classification_labels_abc_large.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug11_model = RandomForestRegressor(bootstrap= True,\n",
    "max_depth= 51,\n",
    "max_features= 'sqrt',\n",
    "min_samples_leaf= 15,\n",
    "min_samples_split= 35,\n",
    "n_estimators= 178)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Aug11_class_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug11_model.fit(x_train_reg[train_labels!=0], y_train_reg[train_labels!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_time =~ 78 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_after_class(Aug11_class_model, x_train_reg, y_train_reg, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not considering the zeros \n",
    "eval_after_class(Aug11_class_model, x_train_reg, y_train_reg, train_labels, include_zeros=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting correlation graph for test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_after_class(Aug11_class_model, x_test_reg, y_test_reg, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_after_class(Aug11_class_model, x_test_reg, y_test_reg, test_labels, include_zeros=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rfrbaseclass'></a>\n",
    "#### Looking at how the BASE random forest model performs after prior classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big = np.load(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/7580_abc_large_expressed.npz\")['arr_0']\n",
    "train_big_labels = np.load(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/7580_abc_large_expressed_labels.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestRegressor()\n",
    "base_model.fit(train_big, np.arcsinh(train_big_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(base_model ,open(\"/mnt/lab_data2/kmualim/Jamboree_data/models/abc_all/test_models/ABC.Score_rfr_base_model.joblib\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = joblib.load(\"/mnt/lab_data2/kmualim/Jamboree_data/models/abc_all/test_models/ABC.Score_rfr_base_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_after_class(base_model, x_test_reg, y_test_reg, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_after_class(base_model, x_test_reg, y_test_reg, test_labels, include_zeros=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bestRFRnoclass'></a>\n",
    "### Best RFR model without classification step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aug9_model = joblib.load(\"/mnt/lab_data2/kmualim/Jamboree_data/scripts/test_models/Aug9_ABC.Score_all_RFR_cv10.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aug9_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(Aug9_model, x_train_reg, np.arcsinh(y_train_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(Aug9_model, x_valid_reg, np.arcsinh(y_valid_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='GBRbase'></a>\n",
    "### Gradient Boosted Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR = GradientBoostingRegressor()\n",
    "GBR.fit(x_train, np.arcsinh(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(GBR, x_train, np.arcsinh(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(GBR, x_valid, np.arcsinh(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(GBR, open(\"GBT/GBR_base_ABC_large.joblib\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='GBRbest'></a>\n",
    "#### Model Aug5 <br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR_aug5 = joblib.load(\"../scripts/ABC.Score_all_GBT_cv10.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR_aug5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(GBR_aug5, x_train, np.arcsinh(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(GBR_aug5, x_valid, np.arcsinh(y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the feature importances of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,1000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig_lasso = go.Figure(data=go.Scatter(x=x, y=lasso.coef_, mode='markers'))\n",
    "fig_lasso.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_ridge = go.Figure(data=go.Scatter(x=x, y=model_ridge.coef_, mode='markers'))\n",
    "fig_ridge.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_rfr = go.Figure(data=go.Scatter(x=x, y=aug11_model.feature_importances_, mode='markers'))\n",
    "fig_rfr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
