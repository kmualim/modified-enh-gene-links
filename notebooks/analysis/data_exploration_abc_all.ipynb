{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents of Notebook: \n",
    "\n",
    "[Link to Initial data paths](#datapaths)\n",
    "<a href='#datapaths'></a>\n",
    "\n",
    "[Link to data processing functions](#dataprocessing)\n",
    "<a href='#dataprocessing'></a>\n",
    "\n",
    "[Metric Functions used for classification](#metricfunctions)\n",
    "<a href='#metricfunctions'></a>\n",
    "\n",
    "#### TLDR: \n",
    "In the initial_model notebook, we looked at the different applied models to the ABC + neural network embeddings dataset. This is a continuation notebook that focusses on data exploration\n",
    "\n",
    "###### Existing datasets: \n",
    "[Regression dataset](#linearregdataset)<a href='#linearregdataset'></a> : \n",
    "\n",
    "Path: /mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/train_valid_test_all/x_train_reg_all.npz\n",
    "Consists of : x_*_reg_all, y_*_reg_all, *_gene_labels_reg_all where * is train, valid, test respectively <br>\n",
    "x_*_reg_all : <br>\n",
    "sizes: Train (16525, 1000), Valid (3120, 1000), Test (1031, 1000) <br>\n",
    "contains sequence embeddings <br>\n",
    "y_*_reg_all : <br>\n",
    "sizes: Train (16525, ), Valid (3120, ), Test (1031, ) : <br>\n",
    "contains corresponding gene expression values in TPM \n",
    "\n",
    "*_gene_labels_reg_all: <br>\n",
    "sizes : Train (16525, ), Valid (3120, ), Test (1031, ) : <br>\n",
    "contains corresponding gene names \n",
    "\n",
    "<b>[Classification dataset]:</b> \n",
    "\n",
    "Path: /mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/train_classification_labels_abc_large.npz\n",
    "consists of: *_classification_labels_abc_large where * is train, valid, test respectively <br>\n",
    "*_classification_labels_abc_large : <br> \n",
    "sizes: Train (16525, 1000), Valid (3120, 1000), Test (1031, 1000) <br>\n",
    "contains binary labels for gene expression for classification model <br>\n",
    "\n",
    "NOTE: classification x inputs (embeddings) can use the ones for regression\n",
    "\n",
    "[JUST expressed genes dataset](#expressedgenespath)<a href='#expressedgenespath'></a><br> \n",
    "\n",
    "\n",
    "\n",
    "### Contents:\n",
    "1. [classification model](#classificationmodel)<a href='#classificationmodel'></a> \n",
    "2. [classification results](#classificationresults)<a href='#classificationresults'></a>\n",
    "3. [Regression dataset used ](#linearregdataset)<a href='#linearregdataset'></a>\n",
    "4. [Path to expressed genes dataset](#expressedgenespath)<a href='#expressedgenespath'></a><br> \n",
    "5. [Linear Regression w prior classification Results](#linregclass)<a href='#linregclass'></a>\n",
    "6. [Linear Regressor w Boosting Algorithm ](#linboostingalgo)<a href='##linboostingalgo'></a><br>\n",
    "6a. [Plot of predicted boosted value](#plotpredicted)<a href='#plotpredicted'></a><br>\n",
    "6b. [Plot of Residual](#plotresidual)<a href='#plotresidual'></a><br>\n",
    "6c. [Variance dsistribution](#variancedistribution)<a href='#variancedistribution'></a><br>\n",
    "7. [GC Percentage correlation with neural network embeddings ](#gccorrelation)<a href='#gccorrelation'></a>\n",
    "8. [Looking at data Distribution of Labels](#datadistribution)<a href='#datadistribution'></a>\n",
    "9. [Threshold at 0.5](#threshold0.5)<a href='#threshold0.5'></a> \n",
    "10. [Threshold at 1.0](#threshold1.0)<a href='#threshold1.0'></a>\n",
    "11. [GC content of the expressed genes and comparing the difference](#gc_interceptande)<a href='#gc_interceptande'></a><br>\n",
    "11a. [Histogram plot of GC percent of neural network embeddings](#histoplot)<a href='#histoplot'></a><br>\n",
    "11b. [Plot of histogram magnitude against GC content](#embedmag)<a href='#embedmag'></a><br>\n",
    "11c. [Histogram plot of embedding distribution](#embeddist)<a href='#embeddist'></a><br>\n",
    "\n",
    "In this notebook, I look at understanding why the linear model isn't fitting the model as well as hoped. \n",
    "\n",
    "I built a [classification model](#classificationmodel)<a href='#classificationmodel'></a> with the corresponding [results](#classificationresults)<a href='#classificationresults'></a> <br> \n",
    "The classification model was able to achieve an accuracy of ~0.7 at predicting whether the gene was on or off based on its weighted embeddings\n",
    "\n",
    "Utilizing the [Regression dataset](#linearregdataset)<a href='#linearregdataset'></a> , \n",
    "I looked at fitting a Linear Regression after prior classification. The linear regression model was trained on ONLY expressed genes. <br> \n",
    "\n",
    "[Path to expressed genes dataset](#expressedgenespath)<a href='#expressedgenespath'></a><br> \n",
    "\n",
    "Linear Regression after classification got rid of the previous vertical line that was previously present in correlation graphs in the initial model notebook. \n",
    "[Results](#linregclass)<a href='#linregclass'></a> \n",
    "\n",
    "A boosting algorithm was applied where at each iteration, the linear regressor was fitted to the residual of y_actual - y_hat. This was done to allow multiple iterations of fitting in the hopes that the final residual would be the noise. \n",
    "[Linear Regressor Boosting](#linboostingalgo)<a href='##linboostingalgo'></a> \n",
    "\n",
    "The \"predicted\" value was plotted against true labels [plot](#plotpredicted)<a href='#plotpredicted'></a>\n",
    "The \"residual\" value was plotted against true labels [plot](#plotresidual)<a href='#plotresidual'></a>\n",
    "\n",
    "The expectation was high correlation of \"Predicted values\" with true labels and poor correlation of residual values with true labels. \n",
    "\n",
    "However, This was not the case .... \n",
    "\n",
    "Time to look at how the variance of the data is being distributed, w.r.t the above plots\n",
    "[Variance dsistribution](#variancedistribution)<a href='#variancedistribution'></a>\n",
    "   \n",
    "Most of the variance of the data is captured in the residual which led us to the conclusion that a linear model could not fit this data well. \n",
    "\n",
    "Do the neural network embeddings correlate highly with GC content of sequence? Could this be the reason why linear regression does not work? \n",
    "[GC Correlation](#gccorrelation)<a href='#gccorrelation'></a>\n",
    "\n",
    "At first glance, you could infer slight correlation. However, I need to do more digging into this. \n",
    "   \n",
    "[Looking at data Distribution of labels](#datadistribution)<a href='#datadistribution'></a> made us realize that fitting a two-part linear model such as a zero-inflated negative binomal or a generalized linear model negative binomial might work better [This is on TODO]\n",
    "\n",
    "Another thing to try was also to artificially Thresholding data distribution of labels: \n",
    "1. [Threshold at 0.5](#threshold0.5)<a href='#threshold0.5'></a> \n",
    "2. [Threshold at 1.0](#threshold1.0)<a href='#threshold1.0'></a>\n",
    "\n",
    "Both these two linear models with the new artificially curated data distribution had an odd [intercept](#whatintercept)<a href='#whatintercept'></a> \n",
    "\n",
    "I looked into [GC content of the expressed genes and comparing the difference](#gc_interceptande)<a href='#gc_interceptande'></a> I looked into the GC content of x inputs of the expressed genes whose predicted value was along the intercept and NOT along the intercept\n",
    "This analysis was done in 3 ways: \n",
    "1. Looking at a [histogram](#histoplot)<a href='#histoplot'></a> plot of these expressed genes a) at the intercept b) not at the intercept \n",
    "2. Looking at the [embedding magnitude](#embedmag)<a href='#embedmag'></a> against the percent GC content and seeing if there is a relationship \n",
    "3. Looking at the [embedding distribution](#embeddist)<a href='#embeddist'></a> \n",
    "The range of values that the input embeddings of the expressed genes a) at the intercept b) not at the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "import pickle\n",
    "import joblib\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='datapaths'></a>\n",
    "#### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = np.load(\"/mnt/lab_data2/kmualim/enhancer_gene_anlysis/datasets/all_dataset/gene_labels_all.npy\", allow_pickle=True)\n",
    "express_1 = pickle.load(open(\"/mnt/lab_data2/kmualim/enhancer_gene_anlysis/datasets/all_dataset/embeddings_all_w_gene.p\",\"rb\"))\n",
    "expression = pd.read_csv(\"/mnt/lab_data2/kmualim/enhancer_gene_anlysis/datasets/K562.Genes.TPM.txt\", sep=\" \", header=None)\n",
    "expression.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataprocessing'></a>\n",
    "#### Functions for combining and splitting data inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Appending labels to expression table \n",
    "## 0 for non-expressed, 0 for expressed\n",
    "label_1=[]\n",
    "for i in expression[1]: \n",
    "    if i>1: \n",
    "        label_1.append(1)\n",
    "    else: \n",
    "        label_1.append(0)\n",
    "\n",
    "expression[2] = label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "def get_expression(express_dict, y_valid_labels): \n",
    "    x_val=[]\n",
    "    for i in y_valid_labels[0]:\n",
    "        x_val.append(express_dict[i])\n",
    "    x_values = np.vstack(x_val)\n",
    "    return x_values\n",
    "    \n",
    "def get_list(y_valid):\n",
    "    y_valid_el = []\n",
    "    for i in y_valid: \n",
    "        y_valid_el.append(i)\n",
    "    return y_valid_el\n",
    "\n",
    "# creating feature spaces \n",
    "def get_train_valid_split(labels, expression_dict, expression, classify=False):\n",
    "    y_train, y_rem = train_test_split(labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "    y_valid, y_test = train_test_split(y_rem, test_size=0.25, random_state=42, shuffle=True)\n",
    "    y_train_el = get_list(y_train) \n",
    "    y_valid_el = get_list(y_valid) \n",
    "    y_test_el = get_list(y_test) \n",
    "    y_train_labels = expression[expression[0].isin(y_train_el)]\n",
    "    y_valid_labels = expression[expression[0].isin(y_valid_el)]\n",
    "    y_test_labels = expression[expression[0].isin(y_test_el)]\n",
    "    x_train = get_expression(expression_dict, y_train_labels)\n",
    "    x_valid = get_expression(expression_dict, y_valid_labels)\n",
    "    x_test = get_expression(expression_dict, y_test_labels)\n",
    "    #if classify: \n",
    "    y_train_c, y_valid_c, y_test_c = get_class_labels(y_train_labels, y_valid_labels, y_test_labels)\n",
    "    #else: \n",
    "    y_train_r, y_valid_r, y_test_r = get_reg_labels(y_train_labels, y_valid_labels, y_test_labels)\n",
    "    return x_train, x_valid, x_test, y_train_r, y_valid_r, y_test_r, y_train_c, y_valid_c, y_test_c\n",
    "\n",
    "def get_class_labels(y_train_labels, y_valid_labels, y_test_labels):\n",
    "        y_train = y_train_labels[2].values\n",
    "        y_valid = y_valid_labels[2].values\n",
    "        y_test = y_test_labels[2].values \n",
    "        return y_train, y_valid, y_test\n",
    "    \n",
    "def get_reg_labels(y_train_labels, y_valid_labels, y_test_labels):\n",
    "        y_train = y_train_labels[1].values\n",
    "        y_valid = y_valid_labels[1].values\n",
    "        y_test = y_test_labels[1].values\n",
    "        return y_train, y_valid, y_test\n",
    "    \n",
    "    \n",
    "    \n",
    "%matplotlib inline\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(y_valid_preds, y_valid): \n",
    "    print(\"Spearman R\", spearmanr(y_valid_preds,np.arcsinh(y_valid)))\n",
    "    print(\"Pearson R\", pearsonr(y_valid_preds,np.arcsinh(y_valid)))\n",
    "    plt.plot(y_valid_preds, np.arcsinh(y_valid), 'ro', markersize=2)\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Correlation graph')\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - np.arcsinh(test_labels))\n",
    "    plot(predictions, test_labels)\n",
    "    #mape = 100 * np.mean(errors / test_labels)\n",
    "    #accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    #print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return errors #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='datafiles'></a>\n",
    "#### Data files and corresponding names for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test, y_train_labels, y_valid_labels, y_test_labels = get_train_valid_split(labels, express_1, expression, classify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"train_classification_labels_abc_large.npz\",train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='metricfunctions'></a>\n",
    "#### metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY PROLLY NOT THE BEST METRIC FOR 2:1 CLASS IMBALANCE \n",
    "def get_accuracy(model, x_train, y_train):\n",
    "    preds = model.predict(x_train)\n",
    "    print(\"Accuracy: \", accuracy_score(y_train, preds))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "def plot_precision_recall_curve(y_preds, y_train): \n",
    "    precision, recall, _ = precision_recall_curve(y_preds, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classificationmodel'></a>\n",
    "#### Building classification model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling genes that have TPM > 0 with a class label =1 , else class label = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figuring out class proportions\n",
    "print(\"Number of labels in class 0: \",len(y_train[y_train==0]))\n",
    "print(\"Number of labels in class 1: \",len(y_train[y_train==1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression CV, CV =10 ， accuracy is ~ 73%\n",
    "log_reg = LogisticRegressionCV(cv=10).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(log_reg, open(\"logreg_abc_large.joblib\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=joblib.load(\"logreg_abc_large.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classificationresults'></a>\n",
    "#### Predicted classifcation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = get_accuracy(log_reg, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = get_accuracy(log_reg, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_preds = get_accuracy(log_reg, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"train_classification_labels_abc_large.npz\",train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"valid_classification_labels_abc_large.npz\",valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"test_classification_labels_abc_large.npz\",test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = np.load(\"train_classification_labels_abc_large.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = np.load(\"valid_classification_labels_abc_large.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.load(\"test_classification_labels_abc_large.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linearregdataset'></a>\n",
    "#### path to Linear regression dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reg, x_valid_reg, x_test_reg, y_train_reg, y_valid_reg, y_test_reg, y_train_labels, y_valid_labels, y_test_labels = get_train_valid_split(labels, express_1, expression, classify=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing all training_data \n",
    "np.savez(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/train_valid_test_all/x_train_reg_all.npz\", x_train_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/x_valid_reg_all.npz\", x_valid_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/x_test_reg_all.npz\", x_test_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/y_train_reg_all.npz\", y_train_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/y_valid_reg_all.npz\", y_valid_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/y_test_reg_all.npz\", y_test_reg)\n",
    "np.savez(\"datasets/train_valid_test_all/train_gene_labels_reg_all.npz\", y_train_labels)\n",
    "np.savez(\"datasets/train_valid_test_all/valid_gene_labels_reg_all.npz\", y_valid_labels)\n",
    "np.savez(\"datasets/train_valid_test_all/test_gene_labels_reg_all.npz\", y_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_after_class(y_valid_preds, y_valid): \n",
    "    print(\"Spearman R\", spearmanr(y_valid_preds,np.arcsinh(y_valid)))\n",
    "    print(\"Pearson R\", pearsonr(y_valid_preds,np.arcsinh(y_valid)))\n",
    "    plt.plot(y_valid_preds, np.arcsinh(y_valid), 'ro', markersize=2)\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Correlation graph')\n",
    "\n",
    "def get_number_of_zeros(test_labels, preds): \n",
    "    num_test_zero=0\n",
    "    num_pred_zero=0\n",
    "    for i in range(len(test_labels)): \n",
    "        if test_labels[i]==0 and preds[i]!=0:\n",
    "            num_test_zero+=1\n",
    "        if test_labels[i]!=0 and preds[i]==0:\n",
    "            num_pred_zero+=1\n",
    "    return num_test_zero, num_pred_zero\n",
    "    \n",
    "def eval_after_class(model, test_features, test_labels, test_class_labels, include_zeros=True):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs((predictions*test_class_labels) - np.arcsinh(test_labels))\n",
    "    final_preds = predictions*test_class_labels\n",
    "    num_test_zero, num_pred_zero = get_number_of_zeros(test_labels, test_class_labels)\n",
    "    if include_zeros:\n",
    "        plot_after_class(final_preds, test_labels)\n",
    "    else: \n",
    "        plot_after_class(final_preds[final_preds!=0], test_labels[final_preds!=0])\n",
    "    #mape = 100 * np.mean(errors / test_labels)\n",
    "    #accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    \n",
    "    print(\"Number of Predictions!=0 and Actual==0:\", num_test_zero)\n",
    "    print(\"Number of Predictions==0 and Actual!=0:\", num_pred_zero)\n",
    "    print(\"Number of total Predictions:\", len(final_preds))\n",
    "    #print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return errors, predictions #accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing only the labels that are 1 \"expressed\" \n",
    "use as input for linear regression \n",
    "\n",
    "Reduces training data from ~16k to just ~7k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rem = x_train_reg[train_preds!=0]\n",
    "y_train_rem = y_train_reg[train_preds!=0]\n",
    "x_valid_rem = x_valid_reg[valid_preds!=0]\n",
    "y_valid_rem = y_valid_reg[valid_preds!=0]\n",
    "x_test_rem = x_test_reg[test_preds!=0]\n",
    "y_test_rem = y_test_reg[test_preds!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and train_labels are the concatenation of training and validation \n",
    "train = np.concatenate((x_train_reg, x_valid_reg))\n",
    "train_labels = np.concatenate((y_train_reg, y_valid_reg))\n",
    "\n",
    "# big_train_class_labels gives the classification labels for expressed and non-expressed genes \n",
    "big_train_class_labels = np.concatenate((train_preds, valid_preds))\n",
    "train_big = train[big_train_class_labels!=0]\n",
    "train_labels_big = train_labels[big_train_class_labels!=0]\n",
    "print(len(train_big))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_big and train_labels_big refer to x and y inputs for expressed_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='expressedgenespath'></a>\n",
    "#### paths to expressed genes datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/7580_abc_large_expressed.npz\", train_big)\n",
    "np.savez(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/7580_abc_large_expressed_labels.npz\", train_labels_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big = np.load(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/7580_abc_large_expressed.npz\")['arr_0']\n",
    "train_labels_big = np.load(\"/mnt/lab_data2/kmualim/Jamboree_data/notebooks/datasets/7580_abc_large_expressed_labels.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_big, x_valid_big, y_train_big, y_valid_big = train_test_split(train_big, train_labels_big, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_big))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linregclass'></a>\n",
    "#### Linear Regression after classification of genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linreg_AFTERCLASS trained on ~ 7500 examples (\"EXPRESSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_AFTERCLASS = LinearRegression()\n",
    "linreg_AFTERCLASS.fit(train_big, np.arcsinh(train_labels_big))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept=linreg_AFTERCLASS.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linreg_AFTERCLASS.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at how linear regression after classification applies to trainin set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, y_hat = eval_after_class(linreg_AFTERCLASS, x_train_reg, y_train_reg, train_preds)\n",
    "plt.xlim(-1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at just the expressed portion of the above graph where vertical line at zero is omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(linreg_AFTERCLASS, x_train_rem, y_train_rem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at how linear regression after classification applies to validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, y_valid_hat = eval_after_class(linreg_AFTERCLASS, x_valid_reg, y_valid_reg, valid_preds)\n",
    "plt.xlim(-1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at just the expressed portion of the above graph where vertical line at zero is omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(linreg_AFTERCLASS, x_valid_rem, np.arcsinh(y_valid_rem))\n",
    "plt.xlim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_intercept = y_hat*train_preds\n",
    "y_hat_v_intercept = y_valid_hat*valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_hat_intercept[y_hat_intercept==intercept]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(y_hat_v_intercept[y_hat_v_intercept==intercept]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linboostingalgo'></a>\n",
    "#### Applying boosting algorithm for Linear regression algorithm for EXPRESSED GENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Running iterations to minimize loss between actual and predictions \n",
    "linreg = LinearRegression()\n",
    "y_next = np.arcsinh(train_labels_big)\n",
    "scored_preds = 0\n",
    "d = {}\n",
    "for t in range(1,20): \n",
    "    linreg.fit(train_big, y_next)\n",
    "    d[t]=linreg.coef_\n",
    "    y_train_preds = linreg.predict(train_big)\n",
    "    scored_preds += y_train_preds\n",
    "    y_next = y_next - y_train_preds \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the magnitude of coefficients of the linear regression at each iteration\n",
    "- it should *technically* be decreasing with each iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fix the underflow overflow problem happeningg here \n",
    "coefficients=[]\n",
    "for i in range(1,20):\n",
    "    total = np.log((d[i]**2)+0.001\n",
    "    coefficients.append(np.sum(total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(1,20,19)\n",
    "plt.plot(x, coefficients, 'ro')\n",
    "plt.xlabel(\"Iteration Number\")\n",
    "plt.ylabel(\"Magnitude of coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cool..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linreg_intercept = linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plotpredicted'></a>\n",
    "#### Plotting \"predicted\" signal against actual signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(scored_preds, train_labels_big)\n",
    "plt.xlim(-10,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plotresidual'></a>\n",
    "#### Plotting \"residual\" signal against actual signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(y_next, train_labels_big)\n",
    "plt.xlim(-10,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(y_next, np.arcsinh(train_labels_big), 'ro')\n",
    "plt.plot(scored_preds, np.arcsinh(train_labels_big), 'bo')\n",
    "plt.xlim(-10,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='variancedistribution'></a>\n",
    "#### Understanding the variance from the residual signal relative to the \"predicted\" and actual signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = (scored_preds - train_labels_big)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = np.sum(scored_preds**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = np.sum(train_labels_big**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np.sum(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Variance of Predictions:\", predictions_1)\n",
    "print(\"Variance of Actual:\", actual)\n",
    "print(\"Variance of Residual:\", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the neural network embeddings really being driven by "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gccorrelation'></a>\n",
    "#### Neural network embeddings correlate strongly with GC content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_content_all = pd.read_csv(\"../scripts/data/cut_5_embeddings_all_GC.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(fname_npz):\n",
    "    data=np.load(fname_npz,allow_pickle=True)\n",
    "    regions=data['bed_entries']\n",
    "    if 'embeddings' in data: \n",
    "        embeddings=data['embeddings']\n",
    "        data_type='embedding'\n",
    "    else:\n",
    "        embeddings=data['deeplift_scores']\n",
    "        data_type='deeplift_scores'\n",
    "    return regions,embeddings,data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,get_embeddings,_ = load_embedding('../scripts/data/k562_dnase_allputative_classification_embeddings.0.-3.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sum_coef = [np.sum(i**2) for i in get_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_content_all['embeddings'] = all_sum_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_GC_content_all = GC_content_all.sort_values(by=['5_pct_gc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Getting the mean and stdev of magnitude coefficient values depending on GC content \n",
    "sort_GC_content_all.groupby(sort_GC_content_all['5_pct_gc']).mean()\n",
    "sort_GC_content_all.groupby(sort_GC_content_all['5_pct_gc']).std()\n",
    "plt.plot(sort_GC_content_all['5_pct_gc'], sort_GC_content_all['embeddings'], 'ro')\n",
    "plt.xlabel('gc percent')\n",
    "plt.ylabel('embeddings magnitude')\n",
    "plt.title('GC content v.s embeddings magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is way too clumpy, let's try to make this better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_GC_content_all.to_csv(\"datasets/sorted_GC_content_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_GC_content_all= pd.read_csv(\"datasets/sorted_GC_content_all.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = sort_GC_content_all.groupby(pd.cut(sort_GC_content_all['5_pct_gc'], np.arange(0,1.1, 0.1))).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_a = [0, 0, 236100, 2564047, 6137750, 3628275, 1383575, 240066, 3759, 0]\n",
    "x = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
    "fig = go.Figure(data=go.Scatter(x=x, y=arr_a))\n",
    "fig.update_layout(title='Histogram of number of sequence embeddings based on percent GC content', \n",
    "                   xaxis_title='Percent of GC',\n",
    "                   yaxis_title='Number of sequence embeddings')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting histogram and Scatter plot of GC content v.s embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_scatter = go.Figure(data=go.Scatter(\n",
    "    x=sort_GC_content_all['5_pct_gc'], \n",
    "    y=sort_GC_content_all['embeddings'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=6, \n",
    "        color=sort_GC_content_all['5_pct_gc'],\n",
    "        colorscale='Viridis', \n",
    "        showscale=True\n",
    "               )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_scatter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GC content and embeddings distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_GC_content_all.groupby(pd.cut(sort_GC_content_all['5_pct_gc'], np.arange(0,1.1, 0.1))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_GC_content_all.groupby(pd.cut(sort_GC_content_all['5_pct_gc'], np.arange(0,1.1, 0.1))).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linreg_AFTERCLASS trained on ~6k examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(linreg_AFTERCLASS, open(\"linreg/linreg_abc_large_after_classification_TPM1.joblib\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting y-intercept of linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#datadistribution'></a>\n",
    "#### Data distribution\n",
    "Plotting the distribution of arcsinh(TPM) values , manually picking out only the values where TPM != 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a lot of the zeros are also from the arcsinh of the thing \n",
    "print(len(y_train_reg[y_train_reg==0]))\n",
    "plt.hist(np.arcsinh(y_train_reg[y_train_reg!=0]), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_TRAIN LABELS are np.arcsinh(TPM) <br>\n",
    "Looking at the distribution, thresholding labels to just consider np.arcsinh(TPM) values above 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_th(y_valid_preds, y_valid): \n",
    "    print(\"Spearman R\", spearmanr(y_valid_preds,y_valid))\n",
    "    print(\"Pearson R\", pearsonr(y_valid_preds,y_valid))\n",
    "    plt.plot(y_valid_preds, y_valid, 'ro', markersize=2)\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Correlation graph')\n",
    "\n",
    "def eval_th(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    plot_th(predictions, test_labels)\n",
    "    #mape = 100 * np.mean(errors / test_labels)\n",
    "    #accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    #print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return errors #accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.arcsinh(y_train_reg)\n",
    "rel = y_val[y_val>0.5]\n",
    "x_train_rel = x_train_reg[y_val>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_1 = np.arcsinh(y_valid_reg)\n",
    "y_val_rel = y_val_1[y_val_1>0.5]\n",
    "x_valid_rel = x_valid_reg[y_val_1>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(rel))\n",
    "print(len(y_val_rel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='threshold0.5'></a>\n",
    "#### Thresholding at np.arcsinh(TPM) = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data distribution at np.arcsinh(TPM) threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(rel, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting linear regression using only TPM y values above a threshold of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_th = LinearRegression()\n",
    "linreg_th.fit(x_train_rel, rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linreg_th.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation graph fit with train predicted and train actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_th(linreg_th, x_train_rel, rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation graph fit with validation predicted and valid actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate(linreg_th, x_valid_rel, y_val_rel)\n",
    "plt.xlim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(linreg_th, open(\"linreg/linreg_threshold_0.5_abc_large.joblib\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='threshold1.0'></a>\n",
    "#### Thresholding at np.arcsinh(TPM) = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_AFTERCLASS = joblib.load(\"linreg/linreg_abc_large_after_classification_TPM1.joblib\")\n",
    "linreg_AFTERCLASS.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_TRAIN LABELS are np.arcsinh(TPM) <br>\n",
    "Thresholding labels to just consider np.arcsinh(TPM) values above 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.arcsinh(y_train_reg)\n",
    "rel = y_val[y_val>1.0]\n",
    "x_train_rel = x_train_reg[y_val>1.0]\n",
    "\n",
    "y_val_1 = np.arcsinh(y_valid_reg)\n",
    "y_val_rel = y_val_1[y_val_1>1.0]\n",
    "x_valid_rel = x_valid_reg[y_val_1>1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of data when thresholded at 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(rel, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting linear regression using only TPM y values above a threshold of 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_th_1 = LinearRegression()\n",
    "linreg_th_1.fit(x_train_rel, rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linreg_th_1.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation graph fit with train predicted and train actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_th(linreg_th_1, x_train_rel, rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation graph fit with valid predicted and valid actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(linreg_th_1, x_valid_rel, y_val_rel)\n",
    "plt.xlim(0,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(linreg_th_1, open(\"linreg/linreg_threshold_1_abc_large.joblib\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='whatintercept'></a>\n",
    "### Investigating mass of same values for genes/data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = joblib.load(\"/mnt/lab_data2/kmualim/Jamboree_data/models/abc_all/test_models/ABC.Score_linreg.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION GRAPH ON TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## y_intercept \n",
    "cept=linreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = linreg.predict(x_train)\n",
    "valid_preds = linreg.predict(x_valid)\n",
    "test_preds = linreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(preds))\n",
    "print(len(preds[preds!=cept]))\n",
    "print(len(preds[preds==cept]))\n",
    "## 4% of total predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(valid_preds))\n",
    "print(len(valid_preds[valid_preds==cept]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_TRAIN_TI is the x_train input of predictions of expressed genes that are along the intercept <br>\n",
    "X_TRAIN_E is the x_train input of the predictions of expressed genes that aren't along the intercept \n",
    "\n",
    "train_TI\n",
    "valid_TI\n",
    "test_TI \n",
    "are train, valid, test values with predicted values == intercept "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labels to investigate\n",
    "x_train_TI= x_train[preds==cept]\n",
    "x_train_E = x_train[preds!=cept]\n",
    "y_train_E = y_train_labels[preds!=cept]\n",
    "#x_valid_T1=\n",
    "#x_test_T1=\n",
    "y_train_TI = y_train_labels[preds==cept]\n",
    "y_valid_TI = y_valid_labels[valid_preds==cept]\n",
    "y_test_TI = y_test_labels[test_preds==cept]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"genes_expressed_genes_and_intercept.npz\", y_train_TI)\n",
    "np.savez(\"genes_expressed_genes_and_not_intercept.npz\", y_train_E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#gc_interceptande'></a>\n",
    "###  Looking at the GC content of y_train_TI and y_train_E and comparing the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genelist = pd.read_csv(\"/mnt/lab_data2/kmualim/Jamboree_data/GeneList.TSS1kb.GC.bed\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genelist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gets the GC content of gene promoters \n",
    "genes_tss = genelist['4_usercol']\n",
    "print(genes_tss[0])\n",
    "genes_tss_GC = genelist['8_pct_gc']\n",
    "print(genes_tss_GC[0])\n",
    "genes_GC = {}\n",
    "\n",
    "for i in range(len(genes_tss)):\n",
    "    genes_GC[genes_tss[i]]= genes_tss_GC[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOOKING AT JUST EXPRESSED GENES\n",
    "y_train_TI_EXPRESSED = y_train_TI[y_train_TI[2]!=0]\n",
    "y_train_E_EXPRESSED = y_train_E[y_train_E[2]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_of_expressed_genes_sq = [np.sum(i**2) for i in x_train_of_expressed_genes]\n",
    "x_genes_E = [np.sum(i**2) for i in x_train_E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"List of train genes that contains expression values == intercept :\", len(train_TI))\n",
    "print(\"List of non-expressed genes :\", len(train_TI[train_TI[2]==0]))\n",
    "print(\"List of valid genes that contains expression values == intercept :\",len(valid_TI))\n",
    "print(\"List of test genes that contains expression values == intercept :\",len(test_TI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are these genes ubiquitously expressed genes ? \n",
    "ubi_e_genes = pd.read_csv(\"/users/kmualim/updated_ABC/ABC-Enhancer-Gene-Prediction/example/config/UbiquitouslyExpressedGenesHG19.txt\", header=None)\n",
    "ubi_e_genes.head()\n",
    "expressed_genes = train_TI[train_TI[2]!=0]\n",
    "\n",
    "\n",
    "x_train_of_expressed_genes = x_train_TI[train_TI[2]!=0]\n",
    "y_train_of_expressed_genes = y_train_TI[train_TI[2]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_TI_val = [genes_GC[i] for i in y_train_of_expressed_genes[0]]\n",
    "genes_E_val = [genes_GC[i] for i in y_train_E[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='histoplot'></a>\n",
    "#### Histogram plots of GC content distribution between expressed genes whose predicted value is AT intercept (Fig1)\n",
    "#### and NOT at intercept (Fig 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the GC content of expressed genes at are NOT the INTERCEPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(genes_E_val, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the GC content distribution of expressed genes at are at the INTERCEPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(genes_TI_val, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='embedmag'></a>\n",
    "#### looking at embeddings magnitude distribution of expressed genes whose predicted value is NOT AT intercept (Fig1) and AT intercept (Fig 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_genes_E, genes_E_val, 'bo')\n",
    "plt.xlabel(\"Magnitude of coefficients\")\n",
    "plt.ylabel(\"Percent of GC content\")\n",
    "plt.title(\"Plot of expressed genes and genes NOT at intercept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x_train_of_expressed_genes_sq, genes_TI_val, 'ro')\n",
    "plt.xlabel(\"Magnitude of coefficients\")\n",
    "plt.ylabel(\"Percent of GC content\")\n",
    "plt.title(\"Plot of expressed genes and genes at intercept\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='embeddist'></a>\n",
    "#### Distribution of embedding values plotted in histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of x_input of expressed and intercept predicted value genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution of x_input of expressed and intercept predicted value genes\n",
    "#print(len(x_train_of_expressed_genes))\n",
    "plt.hist(x_train_of_expressed_genes[1], bins=10, label=1)\n",
    "plt.hist(x_train_of_expressed_genes[73], bins=10, label=73)\n",
    "#plt.hist(x_train_of_expressed_genes[91], bins=10, label=91)\n",
    "#plt.hist(x_train_of_expressed_genes[145], bins=10, label=145)\n",
    "#plt.hist(x_train_of_expressed_genes[163], bins=10, label=163)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution=[]\n",
    "for i in range(len(x_train_of_expressed_genes)):\n",
    "    distribution.append(np.sum(x_train_of_expressed_genes[i])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the sum of the squared distribution of coefficients in the x_input of expressed and intercept predicted value genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(distribution, bins=10)\n",
    "plt.show()\n",
    "print(\"Mean distribution\",np.mean(distribution))\n",
    "print(\"Mean stddev\", np.std(distribution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of values in x_input of expressed and non-intercept predicted value genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution of values in x_input of expressed and non-intercept predicted value genes \n",
    "plt.hist(x_train_E[5], bins=10, label=5)\n",
    "plt.hist(x_train_E[10000], bins=10, label=10000)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_b=[]\n",
    "for i in range(len(x_train_E)):\n",
    "    distribution_b.append(np.sum(x_train_E[i])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the sum of the squared distribution of coefficients in the x_input of expressed and non-intercept predicted value genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(distribution_b, bins=10)\n",
    "plt.show()\n",
    "print(\"Mean distribution\",np.mean(distribution_b))\n",
    "print(\"Mean stddev\", np.std(distribution_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are any of these expressed genes ubiquitously expressed genes?? \n",
    "print(len(expressed_genes[expressed_genes[0].isin(ubi_e_genes)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
